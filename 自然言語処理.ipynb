{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRUoFVNHJObcN61LgP2NZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasaHLabo/PyCode/blob/main/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自然言語処理\n",
        "自然言語処理方法\n",
        "*   形態素解析　　←基本のここを学ぶ\n",
        "*   構文解析\n",
        "*   意味解析\n",
        "*   文脈解析\n",
        "\n",
        "形態素解析とは？\n",
        "単語の切れ目なく書かれた文を形態素，つまり「意味の持つ最小単位」に分解する処理\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T9YPbEwB_VE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.1　Janomeを使用できるようにする"
      ],
      "metadata": {
        "id": "NNdDhyNoqTwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS4GXsDM-5j2",
        "outputId": "5315fd66-e982-41b7-e47f-e3e1f54d7b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.4.2\n"
          ]
        }
      ],
      "source": [
        "pip install janome"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.2　形態素解析（Morphological Analysis）する"
      ],
      "metadata": {
        "id": "r4wyMS_TqcgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer    #janomeのインポート\n",
        "\n",
        "talk=Tokenizer()                            #形態素解析解析器の作成\n",
        "tokens=talk.tokenize('私の名前は真梨子です')  #形態素解析\n",
        "\n",
        "for token in tokens:\n",
        "  print(token)                              #結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTesjcL1A6Z8",
        "outputId": "c0fcc738-8ef4-49d6-8588-474341d02207"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
            "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "真梨子\t名詞,固有名詞,人名,名,*,*,真梨子,マリコ,マリコ\n",
            "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "解析結果を構成するTokenオブジェクトの”リスト”として返される．"
      ],
      "metadata": {
        "id": "2iRBJnqeF4r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.3　個々の解析結果を扱う"
      ],
      "metadata": {
        "id": "8anecxCXzyFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 字句解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です') # 形態素解析\n",
        "\n",
        "print(tokens[0])) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "HukA_PUSs867",
        "outputId": "52a49273-a21a-46e0-ea93-40d272ee7bde"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-e2a7eaf1286d>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(tokens[0])) # 結果の表示\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "解析結果を構成するTokenオブジェクトの”リスト”として返されるため，要素を表示するにはキャスト（型変換）の必要がある．"
      ],
      "metadata": {
        "id": "zJQIN3XXGf2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 字句解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です') # 形態素解析\n",
        "\n",
        "print(list(tokens)[0]) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUGcrC7VB7c6",
        "outputId": "dea1ae8f-680a-40b1-a09e-ce40c8fe0f99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "少し面倒なので，listに変換してしまった方がいいかも"
      ],
      "metadata": {
        "id": "YIDvOV-_y2ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 字句解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です') # 形態素解析\n",
        "\n",
        "tokens=list(tokens)\n",
        "print(tokens[0]) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsXilwQmDDDd",
        "outputId": "1838a144-23a7-4f4e-cb65-007f8832f049"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "リスト7.2だとこんな感じ"
      ],
      "metadata": {
        "id": "kqjH1GMYrBUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 字句解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です') # 形態素解析\n",
        "\n",
        "print(next(tokens)) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9829de78-52aa-4376-b87f-a45a3f6b6d53",
        "id": "gq7OEiLgqpIV"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5K0VqcEosWwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "要素の情報をみる"
      ],
      "metadata": {
        "id": "y65c9TApz5TH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 形態素解析器の作成\n",
        "tokens = talk.tokenize('笑った') # 形態素解析\n",
        "\n",
        "\n",
        "for token in tokens:\n",
        "    print(token) # 結果\n",
        "print('') \n",
        "print('表層形: ' + tokens[0].surface)        # 表層形の表示\n",
        "print('品詞: ' + tokens[0].part_of_speech)  # 品詞の表示\n",
        "print('活用型: ' + tokens[0].infl_type)       # 活用型\n",
        "print('活用形: ' + tokens[0].infl_form)       # 活用形\n",
        "print('基本形: ' + tokens[0].base_form)     # 基本形、見出し語\n",
        "print('読み: ' + tokens[0].reading)           # 読み\n",
        "print('発音: ' + tokens[0].phonetic)          # 発音"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0UORBhFIgyW",
        "outputId": "0a03b192-ca9f-4089-a616-59efd1088446"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "笑っ\t動詞,自立,*,*,五段・ワ行促音便,連用タ接続,笑う,ワラッ,ワラッ\n",
            "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
            "\n",
            "表層形: 笑っ\n",
            "品詞: 動詞,自立,*,*\n",
            "活用型: 五段・ワ行促音便\n",
            "活用形: 連用タ接続\n",
            "基本形: 笑う\n",
            "読み: ワラッ\n",
            "発音: ワラッ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 形態素解析器の作成\n",
        "tokens = talk.tokenize('笑った') # 形態素解析\n",
        "tokens=list(tokens)  #ここがポイント\n",
        "for token in tokens:\n",
        "    print(token) # 結果\n",
        "print('') \n",
        "print('表層形: ' + tokens[0].surface)        # 表層形の表示\n",
        "print('品詞: ' + tokens[0].part_of_speech)  # 品詞の表示\n",
        "print('活用型: ' + tokens[0].infl_type)       # 活用型\n",
        "print('活用形: ' + tokens[0].infl_form)       # 活用形\n",
        "print('基本形: ' + tokens[0].base_form)     # 基本形、見出し語\n",
        "print('読み: ' + tokens[0].reading)           # 読み\n",
        "print('発音: ' + tokens[0].phonetic)          # 発音\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPQGEaG5FLDB",
        "outputId": "9ccf1372-4149-488b-f5cc-65462a3f176c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "笑っ\t動詞,自立,*,*,五段・ワ行促音便,連用タ接続,笑う,ワラッ,ワラッ\n",
            "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
            "\n",
            "表層形: 笑っ\n",
            "品詞: 動詞,自立,*,*\n",
            "活用型: 五段・ワ行促音便\n",
            "活用形: 連用タ接続\n",
            "基本形: 笑う\n",
            "読み: ワラッ\n",
            "発音: ワラッ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分かち書き（表層形だけを取り出す処理）"
      ],
      "metadata": {
        "id": "C_fuMfs6strZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 字句解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です', wakati = True) # 解析\n",
        "\n",
        "print(tokens) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP3Oh4l8I9-T",
        "outputId": "fbcb489c-0666-4d1c-b443-f56357e9a7d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Tokenizer.__tokenize_stream at 0x7f28db3702e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 字句解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です', wakati = True) # 解析\n",
        "tokens=list(tokens)\n",
        "print(tokens) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljE2QSYvG2bf",
        "outputId": "7a233541-cc53-4d92-bc1f-9dcfd7314e07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['私', 'の', '名前', 'は', '真梨子', 'です']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.4 単語の出現回数をカウント"
      ],
      "metadata": {
        "id": "2pB01w36u6Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 形態素解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です') # 解析\n",
        "\n",
        "count = 0\n",
        "for token in tokens:\n",
        "  pos = token.part_of_speech # ‘品詞,品詞細分類1,品詞細分類2,品詞細分類3’\n",
        "  pos = pos.split(',') # カンマで分解する\n",
        "  if pos[0] == '名詞':\n",
        "     print(token)\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhxWMWyW48Mh",
        "outputId": "6dbd5a4c-5e85-4a6b-98ce-caa20286a76d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\n",
            "真梨子\t名詞,固有名詞,人名,名,*,*,真梨子,マリコ,マリコ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "数えた回数を表示してみる"
      ],
      "metadata": {
        "id": "u8uU9-eV5YvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "talk = Tokenizer() # 形態素解析器の作成\n",
        "tokens = talk.tokenize('私の名前は真梨子です') # 解析\n",
        "\n",
        "count = 0\n",
        "for token in tokens:\n",
        "  pos = token.part_of_speech # ‘品詞,品詞細分類1,品詞細分類2,品詞細分類3’\n",
        "  pos = pos.split(',') # カンマで分解する\n",
        "  if pos[0] == '名詞':\n",
        "     print(token)\n",
        "     count+=1\n",
        "print('名詞は'+str(count)+'回出てきました．')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEkjitTds-RC",
        "outputId": "a997861c-7e51-4d41-c8f5-dfb925f54b74"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\n",
            "真梨子\t名詞,固有名詞,人名,名,*,*,真梨子,マリコ,マリコ\n",
            "名詞は3回出てきました．\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "リスト7.6"
      ],
      "metadata": {
        "id": "kstVI60StvRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "text = '私の名前は真梨子です'\n",
        "ana = Analyzer(token_filters = [ POSKeepFilter('名詞') ]) # 解析器の作成、フィルタの指定\n",
        "results = ana.analyze(text) # 解析\n",
        "\n",
        "count = 0\n",
        "for w in results: # フィルタを通過した単語\n",
        "    print(w) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDaKylxi5fRF",
        "outputId": "7dae34a8-91f8-46cc-d6b2-98f9f34696a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\n",
            "真梨子\t名詞,固有名詞,人名,名,*,*,真梨子,マリコ,マリコ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "数えた回数を表示してみる"
      ],
      "metadata": {
        "id": "shNDOhsk5d5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "text = '私の名前は真梨子です'\n",
        "ana = Analyzer(token_filters = [ POSKeepFilter('名詞') ]) # 解析器の作成、フィルタの指定\n",
        "results = ana.analyze(text) # 解析\n",
        "\n",
        "count = 0\n",
        "for w in results: # フィルタを通過した単語\n",
        "    print(w) # 結果の表示\n",
        "    count+=1\n",
        "print('名詞は'+str(count)+'回出てきました．')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qths9ZHtvM1T",
        "outputId": "7c559f6b-16ee-4486-abc1-e5ce85db6569"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\n",
            "真梨子\t名詞,固有名詞,人名,名,*,*,真梨子,マリコ,マリコ\n",
            "名詞は3回出てきました．\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "text = 'ひとつの幸せのドアが閉じる時、もうひとつのドアが開く。\\\n",
        "しかし、よく私たちは閉じたドアばかりに目を奪われ、開いたドアに気付かない。'\n",
        "\n",
        "textfilter = [ POSKeepFilter(['名詞']), TokenCountFilter() ] # フィルタの準備\n",
        "ana = Analyzer(token_filters = textfilter) # 解析器の生成\n",
        "results = ana.analyze(text) # 解析\n",
        "\n",
        "for word, count in results: # 単語と出現回数\n",
        "    print(word, count) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTozid1hyYHs",
        "outputId": "5d8db875-0750-4e1d-bc59-c04023122907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ひとつ 2\n",
            "幸せ 1\n",
            "ドア 4\n",
            "時 1\n",
            "私 1\n",
            "たち 1\n",
            "目 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "text = 'ひとつの幸せのドアが閉じる時、もうひとつのドアが開く。\\\n",
        "しかし、よく私たちは閉じたドアばかりに目を奪われ、開いたドアに気付かない。'\n",
        "\n",
        "textfilter = [ CompoundNounFilter(), POSKeepFilter(['名詞']), TokenCountFilter() ] # フィルタの準備\n",
        "ana = Analyzer(token_filters = textfilter) # 解析器の生成\n",
        "results = ana.analyze(text) # 解析\n",
        "\n",
        "for word, count in results: # 単語と出現回数\n",
        "    print(word, count) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ9E5wsAzr8A",
        "outputId": "bb537bdd-db80-4b57-ef86-9832dd273398"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ひとつ 2\n",
            "幸せ 1\n",
            "ドア 4\n",
            "時 1\n",
            "私たち 1\n",
            "目 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.4.3 解析"
      ],
      "metadata": {
        "id": "D7R2mo4M2d8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path='/content/drive/MyDrive/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xYPYwUS2jCH",
        "outputId": "993a0f7c-4ec9-4c40-e9f7-03b8fd4e0cc5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "file = open(path+'kokoro.txt', 'r', encoding='shift_jis') # ファイルを開く\n",
        "text = file.read() # 読み込む\n",
        "textfilter = [ POSKeepFilter(['名詞']), TokenCountFilter() ] # フィルタの準備\n",
        "ana = Analyzer(token_filters = textfilter) # 解析器の生成\n",
        "results = ana.analyze(text) # 解析\n",
        "\n",
        "sort_text = sorted(results, key=lambda x:x[1], reverse=True) # 結果の並べ替え\n",
        "for i, wc in enumerate(sort_text): # 番号を付ける\n",
        "    if i >= 10: break # 10位まで表示\n",
        "    print((i + 1), ':', wc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WSM1oWw06uN",
        "outputId": "ea8aadec-7e2b-415d-db5f-3dacacebf111"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : ('私', 2700)\n",
            "2 : ('の', 1483)\n",
            "3 : ('先生', 600)\n",
            "4 : ('事', 576)\n",
            "5 : ('よう', 523)\n",
            "6 : ('それ', 409)\n",
            "7 : ('もの', 393)\n",
            "8 : ('人', 390)\n",
            "9 : ('奥さん', 388)\n",
            "10 : ('時', 379)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "file = open(path+'kokoro.txt', 'r', encoding='shift_jis') # ファイルを開く\n",
        "text = file.read() # 読み込む\n",
        "textfilter = [ POSKeepFilter(['形容詞']), TokenCountFilter() ] # フィルタの準備\n",
        "ana = Analyzer(token_filters = textfilter) # 解析器の生成\n",
        "results = ana.analyze(text) # 解析\n",
        "\n",
        "sort_text = sorted(results, key=lambda x:x[1], reverse=True) # 結果の並べ替え\n",
        "for i, wc in enumerate(sort_text): # 番号を付ける\n",
        "    if i >= 10: break # 10位まで表示\n",
        "    print((i + 1), ':', wc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUf-M4w9213y",
        "outputId": "c62fd0dd-9055-4708-ea85-0fb7311f93f1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : ('ない', 288)\n",
            "2 : ('なかっ', 147)\n",
            "3 : ('く', 50)\n",
            "4 : ('いい', 37)\n",
            "5 : ('なく', 35)\n",
            "6 : ('悪い', 35)\n",
            "7 : ('強い', 33)\n",
            "8 : ('若い', 32)\n",
            "9 : ('新しい', 29)\n",
            "10 : ('長い', 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "基本形のみ"
      ],
      "metadata": {
        "id": "8gJwJFlf_wIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.tokenfilter import *\n",
        "\n",
        "file = open(path+'kokoro.txt', 'r', encoding='shift_jis') # ファイルを開く\n",
        "text = file.read() # 読み込む\n",
        "textfilter = [ POSKeepFilter(['形容詞']), TokenCountFilter(att='base_form') ] # フィルタの準備\n",
        "ana = Analyzer(token_filters = textfilter) # 解析器の生成\n",
        "results = ana.analyze(text) # 解析\n",
        "\n",
        "sort_text = sorted(results, key=lambda x:x[1], reverse=True) # 結果の並べ替え\n",
        "for i, wc in enumerate(sort_text): # 番号を付ける\n",
        "    if i >= 10: break # 10位まで表示\n",
        "    print((i + 1), ':', wc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eUZl2Xe68me",
        "outputId": "6575a49a-0e7f-445f-b6ad-45d19049c2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : ('ない', 495)\n",
            "2 : ('悪い', 60)\n",
            "3 : ('くい', 55)\n",
            "4 : ('強い', 52)\n",
            "5 : ('いい', 37)\n",
            "6 : ('若い', 35)\n",
            "7 : ('よい', 35)\n",
            "8 : ('新しい', 34)\n",
            "9 : ('長い', 32)\n",
            "10 : ('早い', 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.5　HTMLタグはずし"
      ],
      "metadata": {
        "id": "4w0Qg7cB7XCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.charfilter import *\n",
        "\n",
        "text = '<div class=‘jisage_5’ style=‘margin-left: 5em’><h4 class=‘naka-midashi’><a class=‘midashi_anchor’ id=‘midashi120’>二</a></h4></div>\\\n",
        "<br />\\\n",
        "　<ruby><rb>私</rb><rp>（</rp><rt>わたくし</rt><rp>）</rp></ruby>がその掛茶屋で先生を見た時は、先生がちょうど着物を脱いでこれから海へ入ろうとするところであった。'\n",
        "ch_set = [UnicodeNormalizeCharFilter(), # UnicodeをNFKC(デフォルト)で正規化\n",
        "     RegexReplaceCharFilter('<rp>\\(.*?\\)</rp>', ''), # ルビを削除\n",
        "     RegexReplaceCharFilter('<.*?>', '')] # HTMLタグを削除\n",
        "\n",
        "ana = Analyzer(char_filters = ch_set) # 解析器の生成\n",
        "tokens = ana.analyze(text) # 解析\n",
        "\n",
        "for token in tokens: # 解析結果の取り出し\n",
        "    print(token) # 結果の表示\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPCYxNKH7YV0",
        "outputId": "09776ab2-e43a-498e-9737-4857cc8b006d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "二\t名詞,数,*,*,*,*,二,ニ,ニ\n",
            " \t記号,空白,*,*,*,*, ,*,*\n",
            "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
            "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
            "その\t連体詞,*,*,*,*,*,その,ソノ,ソノ\n",
            "掛茶屋\t名詞,一般,*,*,*,*,掛茶屋,カケヂャヤ,カケジャヤ\n",
            "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
            "先生\t名詞,一般,*,*,*,*,先生,センセイ,センセイ\n",
            "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
            "見\t動詞,自立,*,*,一段,連用形,見る,ミ,ミ\n",
            "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
            "時\t名詞,非自立,副詞可能,*,*,*,時,トキ,トキ\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "、\t記号,読点,*,*,*,*,、,、,、\n",
            "先生\t名詞,一般,*,*,*,*,先生,センセイ,センセイ\n",
            "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
            "ちょうど\t副詞,一般,*,*,*,*,ちょうど,チョウド,チョード\n",
            "着物\t名詞,一般,*,*,*,*,着物,キモノ,キモノ\n",
            "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
            "脱い\t動詞,自立,*,*,五段・ガ行,連用タ接続,脱ぐ,ヌイ,ヌイ\n",
            "で\t助詞,接続助詞,*,*,*,*,で,デ,デ\n",
            "これから\t副詞,助詞類接続,*,*,*,*,これから,コレカラ,コレカラ\n",
            "海\t名詞,一般,*,*,*,*,海,ウミ,ウミ\n",
            "へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
            "入ろう\t名詞,サ変接続,*,*,*,*,入ろう,ニュウロウ,ニュウロー\n",
            "と\t助詞,格助詞,一般,*,*,*,と,ト,ト\n",
            "する\t動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
            "ところ\t名詞,非自立,副詞可能,*,*,*,ところ,トコロ,トコロ\n",
            "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
            "あっ\t助動詞,*,*,*,五段・ラ行アル,連用タ接続,ある,アッ,アッ\n",
            "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
            "。\t記号,句点,*,*,*,*,。,。,。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.analyzer import Analyzer\n",
        "from janome.charfilter import *\n",
        "\n",
        "text = '<div class=‘jisage_5’ style=‘margin-left: 5em’><h4 class=‘naka-midashi’><a class=‘midashi_anchor’ id=‘midashi120’>二</a></h4></div>\\\n",
        "<br />\\\n",
        "　<ruby><rb>私</rb><rp>（</rp><rt>わたくし</rt><rp>）</rp></ruby><div>がその掛茶屋で先生を見た時は、</div>先生がちょうど着物を脱いでこれから海へ入ろうとするところであった。'\n",
        "ch_set = [UnicodeNormalizeCharFilter(), # UnicodeをNFKC(デフォルト)で正規化\n",
        "     RegexReplaceCharFilter('<rp>\\(.*?\\)</rp>', ''), # ルビを削除\n",
        "     RegexReplaceCharFilter('<.*>', '')] # HTMLタグを削除 比較！！！！\n",
        "\n",
        "ana = Analyzer(char_filters = ch_set) # 解析器の生成\n",
        "tokens = ana.analyze(text) # 解析\n",
        "\n",
        "for token in tokens: # 解析結果の取り出し\n",
        "    print(token) # 結果の表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdwUgwcv8idq",
        "outputId": "455e8190-51bd-4759-fea9-8fabe45bdec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "先生\t名詞,一般,*,*,*,*,先生,センセイ,センセイ\n",
            "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
            "ちょうど\t副詞,一般,*,*,*,*,ちょうど,チョウド,チョード\n",
            "着物\t名詞,一般,*,*,*,*,着物,キモノ,キモノ\n",
            "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
            "脱い\t動詞,自立,*,*,五段・ガ行,連用タ接続,脱ぐ,ヌイ,ヌイ\n",
            "で\t助詞,接続助詞,*,*,*,*,で,デ,デ\n",
            "これから\t副詞,助詞類接続,*,*,*,*,これから,コレカラ,コレカラ\n",
            "海\t名詞,一般,*,*,*,*,海,ウミ,ウミ\n",
            "へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
            "入ろう\t名詞,サ変接続,*,*,*,*,入ろう,ニュウロウ,ニュウロー\n",
            "と\t助詞,格助詞,一般,*,*,*,と,ト,ト\n",
            "する\t動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
            "ところ\t名詞,非自立,副詞可能,*,*,*,ところ,トコロ,トコロ\n",
            "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
            "あっ\t助動詞,*,*,*,五段・ラ行アル,連用タ接続,ある,アッ,アッ\n",
            "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
            "。\t記号,句点,*,*,*,*,。,。,。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.6　ユーザ辞書を用いる"
      ],
      "metadata": {
        "id": "RNwYtJL19y6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "text = Tokenizer() # 形態素解析器の作成\n",
        "tokens = text.tokenize('おじゃる丸は電ボが好き') # 解析\n",
        "\n",
        "for token in tokens:\n",
        "   print(token) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb93x6In-VY7",
        "outputId": "0506df40-6b07-4a54-c874-030f68de81e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "おじゃる\t動詞,自立,*,*,五段・ラ行,基本形,おじゃる,オジャル,オジャル\n",
            "丸\t名詞,一般,*,*,*,*,丸,マル,マル\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "電\t名詞,接尾,一般,*,*,*,電,デン,デン\n",
            "ボ\t名詞,一般,*,*,*,*,ボ,*,*\n",
            "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
            "好き\t名詞,形容動詞語幹,*,*,*,*,好き,スキ,スキ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "text = Tokenizer(path+'userDic.csv', udic_type='simpledic') # 形態素解析器の作成\n",
        "tokens = text.tokenize('おじゃる丸は電ボが好き') # 解析\n",
        "\n",
        "for token in tokens:\n",
        "   print(token) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOgCYnpP-Nex",
        "outputId": "bc6a696a-cfe4-4f2e-dd94-0f1de07ad63c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "おじゃる丸\t名詞,*,*,*,*,*,おじゃる丸,オジャルマル,オジャルマル\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "電ボ\t名詞,*,*,*,*,*,電ボ,デンボ,デンボ\n",
            "が\t接続詞,*,*,*,*,*,が,ガ,ガ\n",
            "好き\t名詞,接尾,形容動詞語幹,*,*,*,好き,スキ,スキ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.7　フィルタ（内容を表示して形式をみる）"
      ],
      "metadata": {
        "id": "0X9_gZrSAxpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://mocobeta.github.io/janome/api/_modules/janome/charfilter.html#CharFilter"
      ],
      "metadata": {
        "id": "Ksyu-eLMGEIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://mocobeta.github.io/janome/api/_modules/janome/tokenfilter.html#TokenCountFilter.apply"
      ],
      "metadata": {
        "id": "3KVVhMuLGF9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnicodeNormalizeCharFilter(CharFilter):\n",
        "    \"\"\"\n",
        "    UnicodeNormalizeCharFilter normalizes Unicode string.\n",
        "\n",
        "    Added in *version 0.3.4*\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, form: str = 'NFKC'):\n",
        "        \"\"\"\n",
        "        Initialize UnicodeNormalizeCharFilter with normalization form.\n",
        "\n",
        "        See also `unicodedata.normalize <https://docs.python.org/3.6/library/unicodedata.html#unicodedata.normalize>`_\n",
        "\n",
        "        :param form: (Optional) normalization form. valid values for *form* are 'NFC', 'NFKC', 'NFD', and 'NFKD'.\n",
        "                     default is 'NFKC'\n",
        "        \"\"\"\n",
        "        self.form = form\n",
        "\n",
        "\n",
        "    def apply(self, text: str) -> str:\n",
        "        return unicodedata.normalize(self.form, text)"
      ],
      "metadata": {
        "id": "d_2ZWRTeAyxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpperCaseFilter(TokenFilter):\n",
        "    \"\"\"\n",
        "    An UpperCaseFilter converts the surface and base_form of tokens to uppercase.\n",
        "\n",
        "    Added in *version 0.3.4*\n",
        "    \"\"\"\n",
        "\n",
        "    def apply(self, tokens: Iterator[Token]) -> Iterator[Token]:\n",
        "        for token in tokens:\n",
        "            token.surface = token.surface.upper()\n",
        "            token.base_form = token.base_form.upper()\n",
        "            yield token"
      ],
      "metadata": {
        "id": "_MeUx4OsDPlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def apply(self, tokens: Iterator[Token]) -> Iterator[Tuple[str, int]]:\n",
        "         token_counts: Dict[str, int] = defaultdict(int)\n",
        "        for token in tokens:\n",
        "            token_counts[getattr(token, self.att)] += 1\n",
        "        if self.sorted:\n",
        "            return ((k, v) for k, v in sorted(token_counts.items(), key=lambda x: x[1], reverse=True))\n",
        "        else:\n",
        "            return ((k, v) for k, v in token_counts.items())"
      ],
      "metadata": {
        "id": "nUKL9xQjvqnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}